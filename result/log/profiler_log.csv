,time_frame,train_configure,infer_configure,status,result
1,1674169876.4709053,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 77, in train
    outputs = model(inputs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/segmentation/_utils.py"", line 23, in forward
    features = self.backbone(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/_utils.py"", line 69, in forward
    x = module(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
2,1674169890.1250632,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 75, in train
    masks = masks.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 11.77 GiB total capacity; 250.38 MiB already allocated; 88.50 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
3,1674169892.1827571,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 51, in train
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
4,1674169893.696551,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
5,1674169895.2337763,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
6,1674169901.874586,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
7,1674169903.407863,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
8,1674169904.9332194,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
9,1674169906.4679885,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
10,1674169913.045393,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
11,1674169914.6547234,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
12,1674169916.1860693,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
13,1674169917.7353332,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 15.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
14,1674169924.9935286,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
15,1674169926.5542266,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
16,1674169928.6804488,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.96 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
17,1674169935.2983727,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
18,1674169937.4928057,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.96 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
19,1674169938.864758,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
20,1674169945.8369327,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
21,1674169947.201508,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
22,1674169949.136009,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
23,1674169956.7101068,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
24,1674169958.7403848,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
25,1674169960.7163506,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
26,1674169968.4250445,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
27,1674169970.4337075,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
28,1674169972.324372,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.96 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 15.44 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
29,1674169978.8453913,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
30,1674169980.227555,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
31,1674169981.5897791,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
32,1674169982.951257,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
33,1674169991.114842,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
34,1674169992.5048888,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
35,1674169993.8693855,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
36,1674169995.2899756,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
37,1674170002.087143,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
38,1674170003.5192232,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
39,1674170004.8937583,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 47, in _create
    model = DetectMultiBackend(path, device=device, fuse=autoshape)  # detection model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 340, in __init__
    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 58, in _create
    model = attempt_load(path, device=device, fuse=False)  # arbitrary model
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/experimental.py"", line 80, in attempt_load
    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 155, in _apply
    self = super()._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 48, in work_infer
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, device = device)  # yolov5n - yolov5x6 or custom
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 542, in load
    model = _load_local(repo_or_dir, model, *args, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/hub.py"", line 572, in _load_local
    model = entry(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 91, in yolov5s
    return _create('yolov5s', pretrained, channels, classes, autoshape, _verbose, device)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/hubconf.py"", line 76, in _create
    raise Exception(s) from e
Exception: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.. Cache may be out of date, try `force_reload=True` or see https://github.com/ultralytics/yolov5/issues/36 for help.
"
40,1674170006.8488994,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 15.38 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
41,1674170010.6472452,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 67, in work_infer
    results = model(image)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py"", line 27, in decorate_context
    return func(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 694, in forward
    y = self.model(x, augment=augment)  # forward
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 504, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 121, in _forward_once
    x = m(x)  # run
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 55, in forward_fuse
    return self.act(self.conv(x))
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 58.96 MiB already allocated; 16.38 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
42,1674170014.4579706,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 67, in work_infer
    results = model(image)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py"", line 27, in decorate_context
    return func(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 694, in forward
    y = self.model(x, augment=augment)  # forward
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 504, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 121, in _forward_once
    x = m(x)  # run
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 55, in forward_fuse
    return self.act(self.conv(x))
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 58.96 MiB already allocated; 14.38 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
43,1674170018.254215,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 67, in work_infer
    results = model(image)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py"", line 27, in decorate_context
    return func(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 694, in forward
    y = self.model(x, augment=augment)  # forward
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 504, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 121, in _forward_once
    x = m(x)  # run
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 55, in forward_fuse
    return self.act(self.conv(x))
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 58.96 MiB already allocated; 14.38 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
44,1674170022.04986,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 67, in work_infer
    results = model(image)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py"", line 27, in decorate_context
    return func(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 694, in forward
    y = self.model(x, augment=augment)  # forward
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 504, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 121, in _forward_once
    x = m(x)  # run
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 55, in forward_fuse
    return self.act(self.conv(x))
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 58.96 MiB already allocated; 14.38 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
45,1674170025.8396237,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'yolo_v5', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/yolo_v5.py"", line 67, in work_infer
    results = model(image)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py"", line 27, in decorate_context
    return func(*args, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 694, in forward
    y = self.model(x, augment=augment)  # forward
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 504, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py"", line 121, in _forward_once
    x = m(x)  # run
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/.cache/torch/hub/ultralytics_yolov5_master/models/common.py"", line 55, in forward_fuse
    return self.act(self.conv(x))
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 58.96 MiB already allocated; 14.38 MiB free; 68.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
46,1674170029.3046963,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
47,1674170043.1030395,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 75, in train
    masks = masks.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 11.77 GiB total capacity; 250.38 MiB already allocated; 44.38 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
48,1674170062.895862,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 75, in train
    masks = masks.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 11.77 GiB total capacity; 274.38 MiB already allocated; 35.75 MiB free; 294.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
49,1674170064.236147,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
50,1674170065.6061835,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
51,1674170066.9638798,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
52,1674170074.1202586,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
53,1674170075.4897196,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
54,1674170076.9207892,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
55,1674170078.3467402,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
56,1674170085.408315,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
57,1674170086.7974443,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
58,1674170088.2715364,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
59,1674170089.6730545,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
60,1674170097.7772896,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
61,1674170098.9692616,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.75 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
62,1674170100.2055357,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
63,1674170101.4489987,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
64,1674170102.689739,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
65,1674170109.8440688,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
66,1674170117.0094092,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
67,1674170118.560779,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
68,1674170120.1212053,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
69,1674170121.6477363,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
70,1674170128.7324722,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
71,1674170130.2235498,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
72,1674170131.8246257,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
73,1674170133.032739,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
74,1674170139.8535411,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
75,1674170141.0582633,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
76,1674170142.2643104,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
77,1674170143.5026278,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
78,1674170144.7391326,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
79,1674170151.9604812,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
80,1674170153.1601582,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
81,1674170154.3521178,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
82,1674170155.5121431,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
83,1674170156.7833192,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.69 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
84,1674170164.931933,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
85,1674170168.067505,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
86,1674170171.1039243,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
87,1674170174.1925738,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
88,1674170177.230402,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
89,1674170180.352922,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
90,1674170183.465579,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'alexnet', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
91,1674170187.2093368,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
92,1674170201.0096126,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 75, in train
    masks = masks.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 11.77 GiB total capacity; 250.38 MiB already allocated; 87.62 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
93,1674170202.962189,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.62 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
94,1674170204.3690498,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.62 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
95,1674170205.8194249,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.62 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
96,1674170212.471046,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
97,1674170213.8659062,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.62 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
98,1674170215.1880975,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.62 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
99,1674170216.5157044,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 18.62 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
100,1674170223.4867675,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
101,1674170225.122524,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
102,1674170226.687607,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
103,1674170228.2750232,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
104,1674170235.0822375,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
105,1674170241.8871946,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
106,1674170243.2284274,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
107,1674170244.6238713,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
108,1674170246.007329,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
109,1674170252.6817694,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
110,1674170254.0442717,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
111,1674170255.4627476,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
112,1674170257.255205,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
113,1674170264.3237522,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
114,1674170271.3509789,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
115,1674170273.269375,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
116,1674170275.1534872,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 18.56 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
117,1674170283.4867063,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 11.77 GiB total capacity; 248.65 MiB already allocated; 93.50 MiB free; 264.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
118,1674170284.910611,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
119,1674170286.2970226,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
120,1674170287.7468996,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
121,1674170294.517931,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
122,1674170301.4005146,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
123,1674170309.264991,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
124,1674170310.5457113,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
125,1674170311.8163614,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
126,1674170313.115747,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
127,1674170314.3782382,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
128,1674170320.8868997,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
129,1674170322.226979,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
130,1674170324.102922,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
131,1674170325.8890848,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 18.50 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
132,1674170329.358529,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
133,1674170332.875254,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
134,1674170336.314223,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
135,1674170339.775188,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'densenet201', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
136,1674170343.5027528,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 77, in train
    outputs = model(inputs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/segmentation/_utils.py"", line 23, in forward
    features = self.backbone(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/_utils.py"", line 69, in forward
    x = module(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
137,1674170357.295134,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 77, in train
    outputs = model(inputs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/segmentation/_utils.py"", line 23, in forward
    features = self.backbone(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/_utils.py"", line 69, in forward
    x = module(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 11.77 GiB total capacity; 402.38 MiB already allocated; 23.12 MiB free; 422.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
138,1674170377.3068419,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 75, in train
    masks = masks.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 11.77 GiB total capacity; 274.38 MiB already allocated; 151.12 MiB free; 294.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
139,1674170378.6487515,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
140,1674170380.0544863,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
141,1674170381.430711,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
142,1674170388.3713255,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
143,1674170389.6832638,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
144,1674170391.008707,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
145,1674170392.6502674,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
146,1674170399.924743,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
147,1674170401.647803,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
148,1674170403.2787232,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
149,1674170404.9553244,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
150,1674170412.9833765,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
151,1674170420.0450957,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
152,1674170420.1905837,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
153,1674170421.527594,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
154,1674170422.9464724,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
155,1674170424.3386667,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
156,1674170432.2946181,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
157,1674170434.0343935,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
158,1674170435.7634313,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
159,1674170437.4095953,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
160,1674170444.801333,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
161,1674170446.5269785,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
162,1674170448.1558168,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.97 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
163,1674170449.5676138,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
164,1674170456.7742505,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
165,1674170458.2074606,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
166,1674170459.6254475,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
167,1674170461.049143,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
168,1674170468.5562456,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
169,1674170469.9709501,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
170,1674170471.4378998,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
171,1674170472.911635,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
172,1674170480.1439176,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
173,1674170480.2606113,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
174,1674170481.6334355,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.49 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
175,1674170483.7176187,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
176,1674170491.5374374,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 11.77 GiB total capacity; 531.04 MiB already allocated; 39.00 MiB free; 534.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
177,1674170493.7765536,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
178,1674170495.9643605,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
179,1674170504.8109891,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 11.77 GiB total capacity; 538.23 MiB already allocated; 19.00 MiB free; 554.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
180,1674170513.8939703,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'mobilenet_v2', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 11.77 GiB total capacity; 547.42 MiB already allocated; 19.00 MiB free; 554.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
181,1674170516.2025,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 51, in train
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
182,1674170518.4493432,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 51, in train
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 20.00 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
183,1674170538.665412,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/deeplab_v3.py"", line 48, in work_train
    train(model, train_loader, val_loader, epoch, device, batch_size)
  File ""../models/deeplab_v3.py"", line 75, in train
    masks = masks.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 11.77 GiB total capacity; 274.38 MiB already allocated; 40.94 MiB free; 294.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
184,1674170545.2623572,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
185,1674170546.9366195,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 19.94 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
186,1674170548.5655878,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 19.94 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
187,1674170550.1734118,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 91.50 KiB already allocated; 19.94 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
188,1674170557.046039,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
189,1674170565.028188,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/alexnet.py"", line 48, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
190,1674170571.7861893,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
191,1674170578.622238,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
192,1674170585.4295735,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/densenet.py"", line 214, in forward
    features = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
193,1674170587.0888503,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 19.88 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
194,1674170588.6996949,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 19.88 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
195,1674170590.3656764,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.91 MiB already allocated; 19.88 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
196,1674170596.98369,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
197,1674170598.3027475,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
198,1674170599.650296,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
199,1674170601.0782144,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
200,1674170607.7251174,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 174, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/mobilenetv2.py"", line 166, in _forward_impl
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
201,1674170609.1226318,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
202,1674170611.1765654,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 19.88 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
203,1674170618.2624657,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 232.28 MiB already allocated; 28.88 MiB free; 244.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
204,1674170625.4207642,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
205,1674170632.4566076,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
206,1674170639.5378237,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
207,1674170641.5723763,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 1.83 MiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
208,1674170642.968593,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
209,1674170644.35541,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 688, in _apply
    self._buffers[key] = fn(buf)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.77 GiB total capacity; 2.00 MiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
210,1674170651.1577394,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 166, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/shufflenetv2.py"", line 155, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
211,1674170652.5192428,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
212,1674170653.8523579,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
213,1674170655.1909666,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
214,1674170661.7788825,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
215,1674170661.8862445,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 209, in main_worker
    model = torch.nn.DataParallel(model).cuda()
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
216,1674170663.2189279,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
217,1674170664.597206,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
218,1674170665.9128366,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
219,1674170672.6335528,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 330, in main_worker
    train(train_loader, model, criterion, optimizer, epoch, device, args)
  File ""../models/cnn_train.py"", line 378, in train
    output = model(images)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 169, in forward
    return self.module(*inputs[0], **kwargs[0])
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/squeezenet.py"", line 95, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
"
220,1674170674.635218,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
221,1674170676.6758943,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_train.py"", line 140, in work
    main_worker(args.gpu, ngpus_per_node, args)
  File ""../models/cnn_train.py"", line 206, in main_worker
    model.features = torch.nn.DataParallel(model.features)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py"", line 148, in __init__
    self.module.to(self.src_device_obj)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.12 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
222,1674170680.3473153,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
223,1674170684.018385,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
224,1674170687.76707,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
225,1674170691.4881668,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'resnet152', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 285, in forward
    return self._forward_impl(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py"", line 268, in _forward_impl
    x = self.conv1(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
226,1674170694.914448,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
227,1674170698.8263009,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
228,1674170701.4615464,"{'arch': 'deeplab_v3', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
229,1674170703.0130265,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
"
230,1674170705.5625956,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
231,1674170708.1535523,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
232,1674170710.6551812,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
233,1674170713.252861,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 67, in work
    model.to(device)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 989, in to
    return self._apply(convert)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 641, in _apply
    module._apply(fn)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 664, in _apply
    param_applied = fn(param)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.77 GiB total capacity; 1017.00 KiB already allocated; 20.06 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
"
234,1674170717.0492208,"{'arch': 'alexnet', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
235,1674170721.1467957,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
236,1674170725.2604902,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
237,1674170729.3922186,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
238,1674170733.5223958,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
239,1674170737.660742,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
240,1674170741.850331,"{'arch': 'densenet201', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution
"
241,1674170746.0092943,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
242,1674170750.1478012,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
243,1674170754.3571076,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
244,1674170758.5081768,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
245,1674170762.7142272,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
246,1674170766.8976336,"{'arch': 'mobilenet_v2', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
247,1674170770.6454127,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
248,1674170774.3894475,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
249,1674170778.0686932,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
250,1674170781.7721677,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
251,1674170785.4947462,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
252,1674170789.2008061,"{'arch': 'resnet152', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
253,1674170793.3935537,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
254,1674170797.5975752,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
255,1674170801.7832484,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
256,1674170805.9187546,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
257,1674170810.120488,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
258,1674170814.1897666,"{'arch': 'shufflenet_v2_x1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
259,1674170818.3462577,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
260,1674170822.4551027,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
261,1674170826.5739994,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
262,1674170830.8671339,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
263,1674170834.9450164,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
264,1674170839.1047566,"{'arch': 'squeezenet1_0', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 69, in forward
    x = self.classifier(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
"
265,1674170842.2316656,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
266,1674170845.3416538,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 2, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
267,1674170848.512819,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 4, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
268,1674170851.6560547,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 8, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
269,1674170854.745357,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 16, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
270,1674170857.9368198,"{'arch': 'vgg16', 'workers': 1, 'epochs': 3, 'batch_size': 32, 'image_size': 224, 'device': 'cuda'}","{'arch': 'vgg16', 'workers': 1, 'batch_size': 1, 'image_size': 224, 'device': 'cuda'}",Fail,"Traceback (most recent call last):
  File ""/home/royliu/Dropbox/research/profile_training_inference_cowork/src/multiprocessing_exception.py"", line 17, in run
    multiprocessing.Process.run(self)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""../models/cnn_infer.py"", line 87, in work
    prd = model.forward(data)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/vgg.py"", line 66, in forward
    x = self.features(x)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py"", line 204, in forward
    input = module(input)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py"", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File ""/home/royliu/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py"", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
"
